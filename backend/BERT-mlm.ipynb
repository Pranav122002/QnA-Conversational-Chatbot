{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetuning BERT using MLM (Masked language Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM, pipeline\n",
    "import torch\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    \"In the heart of a bustling city, technology shapes the way we live, work, and connect with one another.\",\n",
    "    \"Advancements in artificial intelligence are transforming industries and revolutionizing the way we approach problem-solving.\",\n",
    "    \"As we navigate the complexities of the digital age, cybersecurity becomes a paramount concern for safeguarding sensitive information.\",\n",
    "    \"The fusion of creativity and technology gives rise to innovative solutions that push the boundaries of what is possible.\",\n",
    "    \"In the ever-evolving landscape of science and technology, lifelong learning becomes essential for staying relevant and adapting to change.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing dataset\n",
    "tokenized_input = tokenizer(dataset, padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask a percentage of tokens in the dataset\n",
    "# For instance, mask 15% of tokens with '[MASK]' token\n",
    "masked_input = tokenized_input.input_ids.clone()\n",
    "mask_indices = torch.bernoulli(torch.full(masked_input.shape, 0.15)).bool() & (masked_input != tokenizer.pad_token_id)\n",
    "masked_input[mask_indices] = tokenizer.mask_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Loss: 4.921903610229492\n",
      "Epoch 2/3 - Loss: 4.333024024963379\n",
      "Epoch 3/3 - Loss: 4.024721622467041\n",
      "Epoch 4/3 - Loss: 3.8098886013031006\n",
      "Epoch 5/3 - Loss: 3.6359221935272217\n",
      "Epoch 6/3 - Loss: 3.490929365158081\n",
      "Epoch 7/3 - Loss: 3.365839719772339\n",
      "Epoch 8/3 - Loss: 3.2589199542999268\n",
      "Epoch 9/3 - Loss: 3.1668190956115723\n",
      "Epoch 10/3 - Loss: 3.084275722503662\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune the model on the masked language modeling task\n",
    "for epoch in range(10):  \n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(masked_input, labels=masked_input)\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch + 1}/3 - Loss: {loss.item()}\")\n",
    "\n",
    "\n",
    "model.save_pretrained('model/mlm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "model = BertForMaskedLM.from_pretrained('model/mlm')\n",
    "fill_mask = pipeline('fill-mask', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.295559287071228, 'token': 2974, 'token_str': 'technology', 'sequence': 'in the age of technology, technology shapes the way we live'}, {'score': 0.05940323323011398, 'token': 11028, 'token_str': 'invention', 'sequence': 'in the age of invention, technology shapes the way we live'}, {'score': 0.048010826110839844, 'token': 7588, 'token_str': 'computers', 'sequence': 'in the age of computers, technology shapes the way we live'}, {'score': 0.03821643814444542, 'token': 8144, 'token_str': 'innovation', 'sequence': 'in the age of innovation, technology shapes the way we live'}, {'score': 0.01624961383640766, 'token': 6627, 'token_str': 'tech', 'sequence': 'in the age of tech, technology shapes the way we live'}]\n"
     ]
    }
   ],
   "source": [
    "question = \"In the age of [MASK], technology shapes the way we live\"\n",
    "answers = fill_mask(question)\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.22264055907726288, 'token': 2023, 'token_str': 'this', 'sequence': 'this gives rise to innovative solutions'}, {'score': 0.19961273670196533, 'token': 2009, 'token_str': 'it', 'sequence': 'it gives rise to innovative solutions'}, {'score': 0.0417848564684391, 'token': 2008, 'token_str': 'that', 'sequence': 'that gives rise to innovative solutions'}, {'score': 0.0360650010406971, 'token': 2974, 'token_str': 'technology', 'sequence': 'technology gives rise to innovative solutions'}, {'score': 0.029146505519747734, 'token': 8144, 'token_str': 'innovation', 'sequence': 'innovation gives rise to innovative solutions'}]\n"
     ]
    }
   ],
   "source": [
    "question = \"[MASK] gives rise to innovative solutions\"\n",
    "answers = fill_mask(question)\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
